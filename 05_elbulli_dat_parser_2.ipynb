{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_nlg = nx.read_gexf('out/elbulli_nlg_02.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_dat = nx.read_gexf('out/elbulli_dat_03.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spanish_stopwords = set()\n",
    "with open('data/spanish_stopwords.txt') as f:\n",
    "    for line in f:\n",
    "        word = line.strip()\n",
    "        spanish_stopwords.add(word)\n",
    "spanish_stopwords = spanish_stopwords.union(stopwords.words('spanish'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_ingredients_graph = nx.read_gexf('out/spanish_ingredients_lexicon_04.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26871"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ingredients_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingredients = all_ingredients_graph.nodes()\n",
    "ingredients = [i for i in ingredients if i not in spanish_stopwords and len(i) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26865"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aabalone',\n",
       " 'aabalones',\n",
       " 'abacate',\n",
       " 'abacates',\n",
       " 'abadejo',\n",
       " 'abadejo desalado',\n",
       " 'abadejo desalados',\n",
       " 'abadejo fresco',\n",
       " 'abadejo frescos',\n",
       " 'abadejo salado']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(ingredients)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_techniques_graph = nx.read_gexf('out/spanish_techniques_lexicon_04.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4635"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_techniques_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "techniques = all_techniques_graph.nodes()\n",
    "techniques = [t for t in techniques if t not in spanish_stopwords and len(t) > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4622"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(techniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a baja temperatura',\n",
       " 'a bajado temperatura',\n",
       " 'a bajamos temperatura',\n",
       " 'a bajando temperatura',\n",
       " 'a bajar temperatura',\n",
       " 'a baje temperatura',\n",
       " 'a fuego lento',\n",
       " 'a la brasa',\n",
       " 'a la brasa rui',\n",
       " 'a la cazuela']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(techniques)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_split(s):\n",
    "    if '#' in s:\n",
    "        r = s.split('#')\n",
    "    else:\n",
    "        r = s.split('<br>')\n",
    "    return r\n",
    "\n",
    "def my_trim(s):\n",
    "    return ' '.join(nltk.word_tokenize(s))\n",
    "\n",
    "def my_ngrams(s):\n",
    "    ngrms = []\n",
    "    tokens = nltk.word_tokenize(s)\n",
    "    for i in range(1, len(tokens) + 1):\n",
    "        ngrms.extend(ngrams(tokens, i))\n",
    "    return list(map(lambda x: ' '.join(x), ngrms))\n",
    "\n",
    "def in_any(e, es):\n",
    "    return any(map(lambda x: e in x, es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10min 7s, sys: 56 ms, total: 10min 7s\n",
      "Wall time: 10min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for n, data in api.nodes_by_type(g_dat, 'Elaboracion', data=True):\n",
    "    ingrs_str = data['ingrs']\n",
    "    ingrs_str = ingrs_str.lower()\n",
    "    elems = my_split(ingrs_str)\n",
    "    ingrs = map(my_trim, elems)\n",
    "    for ingr in ingrs:\n",
    "        ngrms = my_ngrams(ingr)\n",
    "        ngrms.reverse()\n",
    "        for ngrm in ngrms:\n",
    "            if ngrm in ingredients:\n",
    "                v = ngrm\n",
    "                g_dat.add_node(v, {'label': v, 'nodetype': 'ingrediente'})\n",
    "                g_dat.add_edge(n, v, {'edgetype': 'composicion'})\n",
    "                all_ingredients_graph.node[v]['count'] += 1\n",
    "                break # I assume only one ingredient per split\n",
    "    desc = data['desc']\n",
    "    desc = desc.lower()\n",
    "    elems = my_split(desc)\n",
    "    steps = map(my_trim, elems)\n",
    "    for step in steps:\n",
    "        used_ngrams = set()\n",
    "        ngrms = my_ngrams(step)\n",
    "        ngrms.reverse()\n",
    "        for ngrm in ngrms:\n",
    "            if ngrm in techniques and not in_any(ngrm, used_ngrams):\n",
    "                v = ngrm\n",
    "                g_dat.add_node(v, {'label': v, 'nodetype': 'tecnica'})\n",
    "                g_dat.add_edge(n, v, {'edgetype': 'tecnica'})\n",
    "                all_techniques_graph.node[v]['count'] += 1\n",
    "                used_ngrams.add(ngrm) # I assume one or more techniques per split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38min 25s, sys: 1.56 s, total: 38min 26s\n",
      "Wall time: 38min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for n, data in api.nodes_by_type(g_dat, 'Acabacion', data=True):\n",
    "    desc = data['desc']\n",
    "    desc = desc.lower()\n",
    "    elems = my_split(desc)\n",
    "    steps = map(my_trim, elems)\n",
    "    for step in steps:\n",
    "        used_ingrs_ngrams = set()\n",
    "        used_techs_ngrams = set()\n",
    "        ngrms = my_ngrams(step)\n",
    "        ngrms.reverse()\n",
    "        for ngrm in ngrms:\n",
    "            if ngrm in ingredients and not in_any(ngrm, used_ingrs_ngrams):\n",
    "                v = ngrm\n",
    "                g_dat.add_node(v, {'label': v, 'nodetype': 'ingrediente'})\n",
    "                g_dat.add_edge(n, v, {'edgetype': 'composicion'})\n",
    "                all_ingredients_graph.node[v]['count'] += 1\n",
    "                used_ingrs_ngrams.add(ngrm) # I assume one or more ingredients per split\n",
    "            if ngrm in techniques and not in_any(ngrm, used_techs_ngrams):\n",
    "                v = ngrm\n",
    "                g_dat.add_node(v, {'label': v, 'nodetype': 'tecnica'})\n",
    "                g_dat.add_edge(n, v, {'edgetype': 'tecnica'})\n",
    "                all_techniques_graph.node[v]['count'] += 1\n",
    "                used_techs_ngrams.add(ngrm) # I assume one or more techniques per split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cc in nx.connected_components(all_ingredients_graph):\n",
    "    max_ingr = ''\n",
    "    max_count = 0\n",
    "    total_count = 0\n",
    "    for ingr in cc:\n",
    "        data = all_ingredients_graph.node[ingr]\n",
    "        if data['count'] > max_count:\n",
    "            max_ingr = ingr\n",
    "            max_count = data['count']\n",
    "        total_count += data['count']\n",
    "    if max_ingr:\n",
    "        all_ingredients_graph.node[max_ingr]['repr_count'] = total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for cc in nx.connected_components(all_techniques_graph):\n",
    "    max_tech = ''\n",
    "    max_count = 0\n",
    "    total_count = 0\n",
    "    for tech in cc:\n",
    "        data = all_techniques_graph.node[tech]\n",
    "        if data['count'] > max_count:\n",
    "            max_tech = tech\n",
    "            max_count = data['count']\n",
    "        total_count += data['count']\n",
    "    if max_tech:\n",
    "        all_techniques_graph.node[max_tech]['repr_count'] = total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(g_dat, 'out/elbulli_dat_05.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(all_ingredients_graph, 'out/spanish_ingredients_lexicon_05.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nx.write_gexf(all_techniques_graph, 'out/spanish_techniques_lexicon_05.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

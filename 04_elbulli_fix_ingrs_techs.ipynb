{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import string\n",
    "from collections import defaultdict\n",
    "\n",
    "import networkx as nx\n",
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_nlg = nx.read_gexf('out/elbulli_nlg.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_dat = nx.read_gexf('out/elbulli_dat.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_ingredients_graph = nx.read_gexf('data/spanish_ingredients_lexicon_5.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26743"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ingredients_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlg_ingredients = api.all_ingredients(g_nlg)\n",
    "for ingr in nlg_ingredients:\n",
    "    ingr = ingr.lower()\n",
    "    if ingr not in all_ingredients_graph:\n",
    "        all_ingredients_graph.add_node(ingr, {'count': 0, 'label': ingr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26871"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_ingredients_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3d',\n",
       " 'aabalone',\n",
       " 'aabalones',\n",
       " 'abacate',\n",
       " 'abacates',\n",
       " 'abadejo',\n",
       " 'abadejo desalado',\n",
       " 'abadejo desalados',\n",
       " 'abadejo fresco',\n",
       " 'abadejo frescos']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(all_ingredients_graph.nodes())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_techniques_graph = nx.read_gexf('data/spanish_techniques_lexicon_5.gexf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4372"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_techniques_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlg_techniques = api.all_techniques(g_nlg)\n",
    "for tech in nlg_techniques:\n",
    "    tech = tech.lower()\n",
    "    if tech not in all_techniques_graph:\n",
    "        all_techniques_graph.add_node(tech, {'count': 0, 'label': tech})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4385"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_techniques_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3d',\n",
       " 'a baja temperatura',\n",
       " 'a bajado temperatura',\n",
       " 'a bajamos temperatura',\n",
       " 'a bajando temperatura',\n",
       " 'a bajar temperatura',\n",
       " 'a baje temperatura',\n",
       " 'a fuego lento',\n",
       " 'a la brasa',\n",
       " 'a la brasa rui']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(all_techniques_graph.nodes())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intersect = set(all_ingredients_graph.nodes()).intersection(all_techniques_graph.nodes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3d',\n",
       " 'agua',\n",
       " 'ahumado',\n",
       " 'ahumados',\n",
       " 'encurtido',\n",
       " 'encurtidos',\n",
       " 'ensaladas',\n",
       " 'fetas',\n",
       " 'fresa',\n",
       " 'juliana',\n",
       " 'nitrogeno liquido',\n",
       " 'nitrogeno líquido',\n",
       " 'nitrógeno líquido',\n",
       " 'pluma',\n",
       " 'pure',\n",
       " 'puré',\n",
       " 'sal',\n",
       " 'seca',\n",
       " 'sofrito',\n",
       " 'su',\n",
       " 'tempura',\n",
       " 'teriyaki',\n",
       " 'tsukemono'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_split(s):\n",
    "    if '#' in s:\n",
    "        r = s.split('#')\n",
    "    else:\n",
    "        r = s.split('<br>')\n",
    "    return r\n",
    "\n",
    "def my_trim(s):\n",
    "    return ' '.join(s.split())\n",
    "\n",
    "def my_ngrams(technique):\n",
    "    ngrms = []\n",
    "    tokens = nltk.word_tokenize(technique)\n",
    "    for i in range(1, len(tokens) + 1):\n",
    "        ngrms.extend(ngrams(tokens, i))\n",
    "    return list(map(lambda x: ' '.join(x), ngrms))\n",
    "\n",
    "def in_any(e, es):\n",
    "    return any(map(lambda x: e in x, es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with open('data/es_lexicon.csv') as f:\n",
    "#     reader = csv.reader(\n",
    "#         f,\n",
    "#         delimiter=' ',\n",
    "#     )\n",
    "#     docs = []\n",
    "#     count = 0\n",
    "#     for row in reader:\n",
    "#         for i in range(1, len(row[1:]), 2):\n",
    "#             entry = {}\n",
    "#             entry['flexion'] = row[0].lower()\n",
    "#             entry['lemma'] = row[i].lower()\n",
    "#             entry['eagle'] = row[i+1].lower()\n",
    "#             docs.append(entry)\n",
    "#             count += 1\n",
    "#         if count % 1000 == 0:\n",
    "#             db.es_lexicon.insert_many(docs)\n",
    "#             docs = []\n",
    "#     db.es_lexicon.insert_many(docs)\n",
    "#     docs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 23s, sys: 132 ms, total: 12min 23s\n",
      "Wall time: 12min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "found_ingredients = set()\n",
    "found_techniques = set()\n",
    "\n",
    "for n, data in g_dat.nodes(data=True):\n",
    "    if data['nodetype'] == 'Elaboracion':\n",
    "        ingrs_str = data['ingrs']\n",
    "        elems = my_split(ingrs_str)\n",
    "        ingrs = map(my_trim, elems)\n",
    "        for ingr in ingrs:\n",
    "            ngrms = my_ngrams(ingr)\n",
    "            ngrms.reverse()\n",
    "            for ngrm in ngrms:\n",
    "                if ngrm in ingredients:\n",
    "                    v = ngrm\n",
    "                    found_ingredients.add(v)\n",
    "        desc = data['desc']\n",
    "        elems = my_split(desc)\n",
    "        steps = map(my_trim, elems)\n",
    "        for step in steps:\n",
    "            ngrms = my_ngrams(step)\n",
    "            ngrms.reverse()\n",
    "            for ngrm in ngrms:\n",
    "                if ngrm in techniques:\n",
    "                    v = ngrm\n",
    "                    found_techniques.add(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingrs_techs_nlg = defaultdict(set)\n",
    "for n in g_nlg.nodes():\n",
    "    comps = api.get_components_Recipe(g_nlg, n)\n",
    "    for c in comps:\n",
    "        if c.lower() in intersect:\n",
    "            ingrs_techs_nlg[c].add('i')\n",
    "    techs = api.get_Techniques_Recipe(g_nlg, n)\n",
    "    for t in techs:\n",
    "        if t.lower() in intersect:\n",
    "            ingrs_techs_nlg[t].add('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ingrs_techs_dat = defaultdict(set)\n",
    "for c in found_ingredients:\n",
    "    if c in intersect:\n",
    "        ingrs_techs_dat[c].add('i')\n",
    "for t in found_techniques:\n",
    "    if t in intersect:\n",
    "        ingrs_techs_dat[t].add('t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'agua': {'i'},\n",
       "             'ahumado': {'t'},\n",
       "             'juliana': {'i'},\n",
       "             'sal': {'i'},\n",
       "             'tempura': {'i'}})"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingrs_techs_nlg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'agua': {'i'},\n",
       "             'ahumado': {'t'},\n",
       "             'juliana': {'i'},\n",
       "             'sal': {'i'},\n",
       "             'tempura': {'i'}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingrs_techs_nlg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(set,\n",
       "            {'agua': {'i', 't'},\n",
       "             'ahumado': {'i', 't'},\n",
       "             'ensaladas': {'i', 't'},\n",
       "             'fresa': {'i', 't'},\n",
       "             'juliana': {'i', 't'},\n",
       "             'nitrógeno líquido': {'i', 't'},\n",
       "             'pluma': {'t'},\n",
       "             'puré': {'i', 't'},\n",
       "             'sal': {'i', 't'},\n",
       "             'seca': {'i', 't'},\n",
       "             'sofrito': {'i', 't'},\n",
       "             'su': {'i', 't'}})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ingrs_techs_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From future analysis\n",
    "\n",
    "# nlg\n",
    "# {'agua': {'i'},\n",
    "#  'ahumado': {'t'},\n",
    "#  'juliana': {'i'},\n",
    "#  'sal': {'i'},\n",
    "#  'sofrito': {'i'},\n",
    "#  'tempura': {'i'}}\n",
    "\n",
    "# dat\n",
    "# {'agua': {'i', 't'},\n",
    "#  'ahumado': {'i', 't'},\n",
    "#  'ensaladas': {'i', 't'},\n",
    "#  'fresa': {'i', 't'},\n",
    "#  'juliana': {'i', 't'},\n",
    "#  'nitrógeno líquido': {'i', 't'},\n",
    "#  'pluma': {'t'},\n",
    "#  'puré': {'i', 't'},\n",
    "#  'sal': {'i', 't'},\n",
    "#  'seca': {'i', 't'},\n",
    "#  'sofrito': {'i', 't'},\n",
    "#  'su': {'i', 't'}}\n",
    "\n",
    "# 3d\n",
    "# nlg: Found as Producto\n",
    "# dat: Not found\n",
    "techniques.remove('3d')\n",
    "# agua\n",
    "# nlg: Found as ingrediente and sabor\n",
    "# dat: Found as ingredient and technique\n",
    "techniques.remove('agua')\n",
    "# ahumado\n",
    "# nlg: Found as tecnica\n",
    "# dat: Found as ingredient and technique\n",
    "ingredients.remove('ahumado')\n",
    "# ahumados\n",
    "# nlg: Not found\n",
    "# dat: Not found\n",
    "# Same case as ahumado\n",
    "ingredients.remove('ahumados')\n",
    "# encurtido\n",
    "# nlg: Not found\n",
    "# dat: Not found\n",
    "# Same case as ahumado\n",
    "ingredients.remove('encurtido')\n",
    "# encurtidos\n",
    "# nlg: Not found\n",
    "# dat: Not found\n",
    "# Same case as ahumado\n",
    "ingredients.remove('encurtidos')\n",
    "# ensaladas\n",
    "# nlg: Not found\n",
    "# dat: Found as ingredient and technique\n",
    "ingredients.remove('ensaladas')\n",
    "# fetas\n",
    "# nlg: Not found\n",
    "# dat: Not found\n",
    "techniques.remove('fetas')\n",
    "# fresa\n",
    "# nlg: Found as Producto and sabor\n",
    "# dat: Found as ingredient and technique\n",
    "techniques.remove('fresa')\n",
    "# juliana\n",
    "# nlg: Found as ingrediente\n",
    "# dat: Found as ingredient and technique\n",
    "techniques.remove('juliana')\n",
    "# nitrógeno líquido\n",
    "# nlg: Not found\n",
    "# dat: Found as ingredient and technique\n",
    "ingredients.remove('nitrógeno líquido')\n",
    "# nitrogeno liquido\n",
    "# nlg: Not found (found as Familia Elaboración)\n",
    "# dat: Found as ingredient and technique\n",
    "# Same case as nitrógeno líquido\n",
    "ingredients.remove('nitrogeno liquido')\n",
    "# nitrogeno líquido\n",
    "# nlg: Not found (found as Familia Elaboración)\n",
    "# dat: Found as ingredient and technique\n",
    "# Same case as nitrógeno líquido\n",
    "ingredients.remove('nitrogeno líquido')\n",
    "# pluma\n",
    "# nlg: Not found (found as Familia Elaboración)\n",
    "# dat: Found as technique\n",
    "ingredients.remove('pluma')\n",
    "# pure\n",
    "# nlg: Not found (found as Familia Elaboración)\n",
    "# dat: Found as ingredient and technique\n",
    "# Same case as nitrógeno líquido\n",
    "ingredients.remove('pure')\n",
    "# puré\n",
    "# nlg: Not found (found as Familia Elaboración)\n",
    "# dat: Found as ingredient and technique\n",
    "# Same case as nitrógeno líquido\n",
    "ingredients.remove('puré')\n",
    "# sal\n",
    "# nlg: Found as ingrediente and sabor\n",
    "# dat: Found as ingredient and technique\n",
    "techniques.remove('sal')\n",
    "techniques.append('en sal')\n",
    "# seca\n",
    "# nlg: Not found\n",
    "# dat: Found as ingredient and technique\n",
    "ingredients.remove('seca')\n",
    "# sofrito\n",
    "# nlg: Not found\n",
    "# dat: Found as ingredient and technique\n",
    "ingredients.remove('sofrito')\n",
    "# su\n",
    "# nlg: Not found\n",
    "# dat: Found as ingredient and technique\n",
    "ingredients.remove('su')\n",
    "techniques.remove('su')\n",
    "# tempura\n",
    "# nlg: Found as ingrediente\n",
    "# dat: Not found\n",
    "techniques.remove('tempura')\n",
    "techniques.append('en tempura')\n",
    "# teriyaki\n",
    "# nlg: Not found\n",
    "# dat: Not found\n",
    "ingredients.remove('teriyaki')\n",
    "# tsukemono\n",
    "# nlg: Not found\n",
    "# dat: Not found\n",
    "# Same case as teriyaki\n",
    "ingredients.remove('tsukemono')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26927"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ingredients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4383"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(techniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('out/ingredients.pickle', 'wb') as f:\n",
    "    pickle.dump(ingredients, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('out/techniques.pickle', 'wb') as f:\n",
    "    pickle.dump(techniques, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
